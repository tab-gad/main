# ResAD for Tabular Data ğŸ“Š

A comprehensive implementation of ResAD framework adapted for tabular anomaly detection using TabPFN embeddings.

## ğŸ¯ Overview

This project adapts the ResAD framework for tabular data by combining three key components:

1. ** Pre-trained Feature Extractor**: TabPFN for generating rich embeddings
2. ** Feature Constraintor**: Learnable transformation to enhance anomaly-relevant features  
3. ** Normal Distribution Estimator**: Estimates normal data distribution for anomaly scoring

## Validation

- 12/16: data cross domain - tabpfn embeddingê¹Œì§€ í™•ì¸

## ğŸ—ï¸ Architecture

```
Tabular Data â†’ TabPFN Extractor â†’ Feature Constraintor â†’ Distribution Estimator â†’ Anomaly Scores
     â†“              â†“                     â†“                      â†“
   Raw Features   Rich Embeddings    Constrained Embeddings   Likelihood Scores
``


### Key Components

### 1. Pre-trained Feature Extractor (TabPFN)
- **ì—­í• **: ì›ë³¸ tabular ë°ì´í„°ë¥¼ embeddingìœ¼ë¡œ ë³€í™˜
- **êµ¬ì„±**
  - `TabPFNFeatureExtractor`: ë‹¨ì¼ ì„¤ì • ê¸°ë°˜ embedding
  - `MultiScaleTabPFNExtractor`: ì—¬ëŸ¬ ì„¤ì •ì„ ì´ìš©í•œ multi-scale embedding
- **íŠ¹ì§•**
  - ì‚¬ì „í•™ìŠµ TabPFN í™œìš©
  - supervised / unsupervised ì„¤ì • ëª¨ë‘ ì§€ì›

---

### 2. Feature Constraintor
- **ì—­í• **: feature ë³€ë™ì„±ì„ ì¤„ì—¬ ì •ìƒ íŒ¨í„´ì˜ ê³µí†µ êµ¬ì¡°ë¥¼ ê°•ì¡°
- **êµ¬ì„±**
  - `TabularFeatureConstraintor`: MLP ê¸°ë°˜ ì œì•½
  - `ResidualConstraintor`: ResAD ìŠ¤íƒ€ì¼ residual ë³€í™˜
  - `AdaptiveConstraintor`: ì…ë ¥ì— ë”°ë¼ ì œì•½ ê°•ë„ ì¡°ì ˆ
  - `MultiScaleConstraintor`: multi-scale embedding í†µí•©
- **ì˜ë¯¸**
  - â€œvariationì—ì„œ invarianceë¥¼ ì¶”ì¶œâ€í•˜ê¸° ìœ„í•œ í•µì‹¬ ë‹¨ê³„

---

### 3. Normal Distribution Estimator
- **ì—­í• **: ì •ìƒ ë°ì´í„° ë¶„í¬ë¥¼ í•™ìŠµí•˜ê³  ì´ìƒ ì ìˆ˜ ê³„ì‚°
- **êµ¬ì„±**
  - `NormalDistributionEstimator`: Gaussian + Mahalanobis distance
  - `FlowBasedEstimator`: normalizing flow ê¸°ë°˜ ë¶„í¬ ì¶”ì •
  - `EnsembleEstimator`: ì—¬ëŸ¬ ì¶”ì •ê¸°ì˜ ê²°í•©
- **ì¶œë ¥**
  - anomaly score (likelihood ë˜ëŠ” distance ê¸°ë°˜)


## ğŸ“ Project Structure

```
resad_table/
â”œâ”€â”€ models/                          # Core model components
â”‚   â”œâ”€â”€ tabpfn_extractor.py         # TabPFN-based feature extraction
â”‚   â”œâ”€â”€ constraintor.py             # Feature constraint modules
â”‚   â””â”€â”€ estimator.py                # Distribution estimation modules
â”œâ”€â”€ datasets/                       # Data loading and preprocessing
â”‚   â””â”€â”€ tabular_loader.py           # ADBench and custom dataset support
â”œâ”€â”€ resad_tabular.py                # Main ResAD implementation
â”œâ”€â”€ run_all.py                      # Complete pipeline execution
â””â”€â”€ README.md                       # This file
```

## ğŸš€ Quick Start

### Installation

```bash
# Install required packages
pip install tabpfn-extensions
```

### Basic Usage

```python
# Simple single-dataset experiment
python resad_tabular.py --dataset breastw --mode single_domain

# Cross-domain experiment  
python resad_tabular.py --mode cross_domain --source_datasets breastw pima --target_dataset wdbc

# Complete pipeline with all experiments
python run_all.py --experiment all
```

### Advanced Configuration

```python
# Custom ResAD configuration
python resad_tabular.py \
    --dataset wdbc \
    --use_multiscale \
    --constraintor_type residual \
    --estimator_type flow \
    --epochs 100 \
    --batch_size 128 \
    --lr 5e-4
```

## ğŸ“Š Supported Datasets

The framework supports ADBench datasets and custom tabular datasets:

- **ADBench**: breastw, pima, wdbc, wine, cardio, glass, hepatitis, cover
- **Custom**: Any CSV/Parquet file with features and `is_anomaly` column
- **NPZ**: Standard ADBench format with X and y arrays

## ğŸ§ª Experiments

### 1. Single-Domain Evaluation
```bash
python run_all.py --experiment single_domain
```
Evaluates ResAD on individual datasets with train/test splits.

### 2. Cross-Domain Evaluation  
```bash
python run_all.py --experiment cross_domain
```
Tests generalization by training on source datasets and evaluating on target datasets.

### 3. Ablation Studies
```bash
python run_all.py --experiment ablation
```
Analyzes contribution of different components:
- Multi-scale vs single-scale extraction
- Different constraintor types
- Various distribution estimators

### 4. Parameter Sensitivity
```bash
python run_all.py --experiment sensitivity  
```
Studies impact of hyperparameters:
- Learning rate, batch size, epochs
- Regularization weights
- TabPFN configurations

## ğŸ”§ Configuration Options

### Feature Extractor Options
```python
--use_multiscale          # Enable multi-scale TabPFN extraction
--n_scales 3              # Number of scales for multi-scale
--n_estimators 1          # Number of TabPFN estimators  
--n_fold 5                # Cross-validation folds for TabPFN
--use_scaler              # Apply feature scaling
```

### Constraintor Options
```python
--constraintor_type residual    # Type: basic|residual|adaptive
--num_residual_blocks 3         # Number of residual blocks
--dropout_rate 0.1              # Dropout rate for regularization
```

### Estimator Options
```python
--estimator_type normal         # Type: normal|flow|ensemble
--num_flows 4                   # Number of normalizing flow layers
--num_ensemble_estimators 3     # Ensemble size
```

### Training Options
```python
--epochs 50                     # Training epochs
--batch_size 64                 # Batch size
--lr 1e-3                       # Learning rate
--reg_weight 1e-4               # L2 regularization weight
```

## ğŸ“ˆ Results and Analysis

### Output Files

After running experiments, results are saved in timestamped directories:

```
results/run_YYYYMMDD_HHMMSS/
â”œâ”€â”€ single_domain_results.csv          # Single-domain performance
â”œâ”€â”€ cross_domain_results.csv           # Cross-domain performance  
â”œâ”€â”€ ablation_results.csv               # Component ablation
â”œâ”€â”€ sensitivity_results.json           # Parameter sensitivity
â”œâ”€â”€ complete_results.json              # All detailed results
â””â”€â”€ *.png                              # Visualization plots
```

### Performance Metrics

- **AUC (Area Under ROC Curve)**: Overall discrimination capability
- **AP (Average Precision)**: Performance on imbalanced data
- **Execution Time**: Computational efficiency

### Visualization

The pipeline automatically generates:
- Performance comparison plots
- Cross-domain transfer analysis
- Ablation study visualizations  
- Parameter sensitivity curves

## ğŸ”¬ Technical Details

### TabPFN Integration

TabPFN provides powerful pre-trained representations for tabular data:

```python
# Extract embeddings with TabPFN
embedder = TabPFNEmbedding(tabpfn_clf=TabPFNClassifier(), n_fold=5)
embeddings = embedder.get_embeddings(X_train, y_train, X_test, data_source="test")
```

Key benefits:
- Pre-trained on diverse synthetic tabular data
- Handles mixed data types naturally
- Provides rich semantic embeddings

### Constraint Learning

Feature constraintors learn to emphasize anomaly-relevant patterns:

```python
# Residual constraint learning
class ResidualConstraintor(nn.Module):
    def forward(self, embeddings):
        residual = self.residual_blocks(embeddings)
        return embeddings + residual  # Residual connection
```

Loss function combines:
- Information preservation (cosine similarity)
- Transformation magnitude
- Compactness for normal samples

### Distribution Estimation

Multiple approaches for modeling normal data distribution:

```python
# Gaussian assumption
scores = -log_likelihood_normal(embeddings, mean, covariance)

# Normalizing flows
z, log_det = normalizing_flow(embeddings)  
scores = -log_likelihood_base(z) - log_det
```

## ğŸ› ï¸ Customization

### Adding New Datasets

```python
# Custom dataset class
class CustomDataset(TabularAnomalyDataset):
    def _load_data(self):
        # Implement custom loading logic
        self.X = load_features()
        self.y = load_labels()
        self.feature_names = get_feature_names()
```

### Custom Constraintors

```python
class MyConstraintor(nn.Module):
    def __init__(self, embedding_dim):
        super().__init__()
        self.transform = nn.Sequential(...)
    
    def forward(self, embeddings):
        return self.transform(embeddings)
```

### Custom Estimators

```python  
class MyEstimator(nn.Module):
    def fit(self, embeddings):
        # Learn distribution from normal embeddings
        pass
    
    def forward(self, embeddings):
        # Return anomaly scores
        return scores
```

## ğŸ“Š Example Results

Typical performance on ADBench datasets:

| Dataset | Single-Domain AUC | Cross-Domain AUC |
|---------|-------------------|------------------|
| breastw | 0.0 Â± 0.0    | 0.0 Â± 0.0    |


### Ablation Study Results

| Component | AUC Impact |
|-----------|------------|
| Baseline | 0.0      |
| + Multi-scale | +0.0 |
| + Residual Constraintor | +0.0 |
| + Flow Estimator | +0.0 |



## ğŸ“š References

- **ResAD Paper**: [ResAD: A Simple Framework for Class Generalizable Anomaly Detection](https://arxiv.org/abs/2410.20047)
- **TabPFN Paper**: [TabPFN: A Transformer that Solves Small Tabular Classification Problems in a Second](https://arxiv.org/abs/2207.01848)
- **ADBench**: [ADBench: Anomaly Detection Benchmark](https://github.com/Minqi824/ADBench)
