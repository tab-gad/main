{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65b2ff3a",
   "metadata": {},
   "source": [
    "# Tabular GAD 실험 (ADBench + TabPFN + LLM Embedding)\n",
    "\n",
    "- 다음 3가지 표현을 만들어 anomaly detection / generalization 성능을 비교\n",
    "\n",
    "1) Raw X: 원본 tabular feature\n",
    "2) TabPFN-Residual: TabPFN으로 각 column을 다른 column으로 예측 → 샘플별 residual vector 생성\n",
    "3) LLM-ColumnEmb → RowPooling: 컬럼 분포 요약 텍스트를 임베딩(Qwen3 Embedding) → row 값을 가중치로 풀링하여 row embedding 생성\n",
    "\n",
    "평가:\n",
    "- In-domain AD: 같은 데이터셋에서 train(inlier-only) → test(mixed)\n",
    "- Cross-domain GAD: source dataset에서 학습한 anomaly scorer를 target datasets에 적용\n",
    "\n",
    "기본 anomaly scorer: 일단 IsolationForest (높을수록 anomaly)\n",
    "(이후 ResAD로 scorer 부분만 교체예정)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "13cbc075",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch: 2.7.1+cu118\n",
      "CLASSICAL_DIR = /home/haeylee/main/Classical\n"
     ]
    }
   ],
   "source": [
    "import os, glob, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "import torch\n",
    "print(\"torch:\", torch.__version__)\n",
    "\n",
    "CLASSICAL_DIR = \"/home/haeylee/main/Classical\"\n",
    "print(\"CLASSICAL_DIR =\", CLASSICAL_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "87cf57a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found datasets: 47\n",
      "Examples: ['10_cover', '11_donors', '12_fault', '13_fraud', '14_glass', '15_Hepatitis', '16_http', '17_InternetAds', '18_Ionosphere', '19_landsat', '1_ALOI', '20_letter', '21_Lymphography', '22_magic.gamma', '23_mammography']\n"
     ]
    }
   ],
   "source": [
    "# 데이터셋확인\n",
    "def list_npz_datasets(root=CLASSICAL_DIR):\n",
    "    files = sorted(glob.glob(os.path.join(root, \"*.npz\")))\n",
    "    names = [os.path.splitext(os.path.basename(f))[0] for f in files]\n",
    "    return names, files\n",
    "\n",
    "DATASET_NAMES, DATASET_FILES = list_npz_datasets()\n",
    "print(\"Found datasets:\", len(DATASET_NAMES))\n",
    "print(\"Examples:\", DATASET_NAMES[:15])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0eb3526",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 로더, seed, split, 표준화\n",
    "\n",
    "def set_seed(seed=0):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "def load_npz(dataset_name, root=CLASSICAL_DIR):\n",
    "    path = os.path.join(root, f\"{dataset_name}.npz\")\n",
    "    assert os.path.isfile(path), f\"파일 없음: {path}\"\n",
    "    data = np.load(path, allow_pickle=True)\n",
    "    X = np.asarray(data[\"X\"], dtype=np.float32)\n",
    "    y = np.asarray(data[\"y\"]).astype(int)\n",
    "\n",
    "    # y가 {0,1} 아닐 때 보정(ADBench는 보통 0=normal, 1=anomaly)\n",
    "    uniq = np.unique(y)\n",
    "    if not (len(uniq) == 2 and set(uniq) == {0,1}):\n",
    "        y0 = np.min(uniq)\n",
    "        y = (y != y0).astype(int)\n",
    "\n",
    "    X = np.nan_to_num(X, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "    return X, y\n",
    "\n",
    "def od_split_inlier_train(X, y, seed=0, test_size=0.2):\n",
    "    # 전체 stratified split\n",
    "    X_tr, X_te, y_tr, y_te = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=seed, stratify=y\n",
    "    )\n",
    "    # OD 세팅: train은 정상(inlier=0)만 사용\n",
    "    X_tr_in = X_tr[y_tr == 0]\n",
    "    return X_tr_in, X_te, y_te\n",
    "\n",
    "def standardize_fit_on_train(X_train_inlier, X_any):\n",
    "    scaler = StandardScaler()\n",
    "    Xtr = scaler.fit_transform(X_train_inlier)\n",
    "    Xany = scaler.transform(X_any)\n",
    "    return Xtr, Xany, scaler\n",
    "\n",
    "def metrics(y_true, anomaly_score):\n",
    "    return {\n",
    "        \"auroc\": float(roc_auc_score(y_true, anomaly_score)),\n",
    "        \"auprc\": float(average_precision_score(y_true, anomaly_score)),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad917899",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset: 4_breastw\n",
      "X shape: (683, 9) dtype: float32\n",
      "y shape: (683,) unique: (array([0, 1]), array([444, 239]))\n",
      "\n",
      "X[0] first 10 dims: [5. 1. 1. 1. 2. 1. 3. 1. 1.]\n",
      "y[0:20]: [0 0 0 0 0 1 0 0 0 0 0 0 1 0 1 1 0 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "# 예시\n",
    "\n",
    "set_seed(0)\n",
    "dataset_name = \"4_breastw\"\n",
    "X, y = load_npz(dataset_name)\n",
    "\n",
    "print(\"dataset:\", dataset_name)\n",
    "print(\"X shape:\", X.shape, \"dtype:\", X.dtype)\n",
    "print(\"y shape:\", y.shape, \"unique:\", np.unique(y, return_counts=True))\n",
    "\n",
    "# 샘플 몇 개 보기\n",
    "print(\"\\nX[0] first 10 dims:\", X[0, :10])\n",
    "print(\"y[0:20]:\", y[:20])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ca72cf92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xtr_in (inlier-only) shape: (355, 9)\n",
      "Xte shape: (137, 9)  yte ratio: 0.35036496350364965\n",
      "After standardize:\n",
      "  Xtr_in_s mean (first 5 dims): [ 1.08127864e-07  1.15851284e-08 -1.28275914e-07 -7.00144724e-08\n",
      "  1.57238730e-07]\n",
      "  Xtr_in_s std  (first 5 dims): [1.0000005  0.9999985  0.99999815 0.99999875 0.9999991 ]\n",
      "  Xte_s[0] first 10 dims: [-1.1402882  -0.37100318 -0.45178962 -0.3580195  -1.285264   -0.28385895\n",
      "  0.8608856  -0.26681283 -0.1348383 ]\n"
     ]
    }
   ],
   "source": [
    "Xtr_in, Xte, yte = od_split_inlier_train(X, y, seed=0, test_size=0.2)\n",
    "print(\"Xtr_in (inlier-only) shape:\", Xtr_in.shape)\n",
    "print(\"Xte shape:\", Xte.shape, \" yte ratio:\", yte.mean())\n",
    "\n",
    "Xtr_in_s, Xte_s, scaler = standardize_fit_on_train(Xtr_in, Xte)\n",
    "print(\"After standardize:\")\n",
    "print(\"  Xtr_in_s mean (first 5 dims):\", Xtr_in_s.mean(axis=0)[:5])\n",
    "print(\"  Xtr_in_s std  (first 5 dims):\", Xtr_in_s.std(axis=0)[:5])\n",
    "print(\"  Xte_s[0] first 10 dims:\", Xte_s[0,:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a7b37bef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IForest metrics: {'auroc': 0.9906367041198502, 'auprc': 0.9819594265365031}\n",
      "anomaly score sample: [0.36572993 0.82083933 0.41430815 0.33062756 0.33316394 0.76056935\n",
      " 0.7691908  0.33107951 0.33062756 0.43313967]\n"
     ]
    }
   ],
   "source": [
    "# baseline : isolationforest (raw 표준화 feature)\n",
    "\n",
    "def fit_iforest(X_train, seed=0):\n",
    "    model = IsolationForest(\n",
    "        n_estimators=500,\n",
    "        contamination=\"auto\",\n",
    "        random_state=seed,\n",
    "        n_jobs=-1,\n",
    "    )\n",
    "    model.fit(X_train)\n",
    "    return model\n",
    "\n",
    "def score_iforest(model, X_test):\n",
    "    # score_samples 높을수록 정상 → anomaly score는 부호반전\n",
    "    return -model.score_samples(X_test)\n",
    "\n",
    "m_if = fit_iforest(Xtr_in_s, seed=0)\n",
    "s_if = score_iforest(m_if, Xte_s)\n",
    "print(\"IForest metrics:\", metrics(yte, s_if))\n",
    "print(\"anomaly score sample:\", s_if[:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fddde5a8",
   "metadata": {},
   "source": [
    "#### TabPFN을 OD에 적용 : 관계 기반 residual 만들기\n",
    "- “column 간 relation”을 TabPFN이 피처 예측기로 학습하도록 해서, 각 샘플에서 **관계가 깨진 정도(residual 벡터)**를 만들기\n",
    "- inlier train으로만 학습\n",
    "- 임의로 K개 column을 뽑아서, 각 column을 나머지 column으로 예측\n",
    "- 테스트에서 예측 오차(residual)를 모아 z(x) ∈ R^K 구성\n",
    "- z(x) 위에서 IForest 같은 scorer로 anomaly score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2a5a1434",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tabpfn package version: 6.0.6\n",
      "Has ModelVersion.V2_5 ? True\n",
      "ModelVersion members: ['V2', 'V2_5']\n"
     ]
    }
   ],
   "source": [
    "import tabpfn\n",
    "print(\"tabpfn package version:\", getattr(tabpfn, \"__version__\", \"unknown\"))\n",
    "\n",
    "from tabpfn import TabPFNClassifier, TabPFNRegressor\n",
    "from tabpfn.constants import ModelVersion\n",
    "\n",
    "print(\"Has ModelVersion.V2_5 ?\", hasattr(ModelVersion, \"V2_5\"))\n",
    "print(\"ModelVersion members:\", [m for m in dir(ModelVersion) if m.startswith(\"V\")])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "61035799",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_target_columns_by_variance(X_inlier, k=8, seed=0):\n",
    "    # variance 큰 컬럼 위주로(너무 상수 같은 컬럼 피하려고)\n",
    "    rng = np.random.default_rng(seed)\n",
    "    var = X_inlier.var(axis=0)\n",
    "    idx = np.argsort(-var)\n",
    "    idx = idx[var[idx] > 1e-8]\n",
    "    if len(idx) < k:\n",
    "        # fallback: 랜덤\n",
    "        all_idx = np.arange(X_inlier.shape[1])\n",
    "        rng.shuffle(all_idx)\n",
    "        return all_idx[:k].tolist()\n",
    "    return idx[:k].tolist()\n",
    "\n",
    "def tabpfn_regressor_v25():\n",
    "    # API 호환용(버전에 따라 메서드 이름이 다를 수 있어서 안전하게)\n",
    "    if hasattr(TabPFNRegressor, \"get_default_for_version\"):\n",
    "        return TabPFNRegressor.get_default_for_version(ModelVersion.V2_5)\n",
    "    if hasattr(TabPFNRegressor, \"create_default_for_version\"):\n",
    "        return TabPFNRegressor.create_default_for_version(ModelVersion.V2_5)\n",
    "    # 최신 기본이 2.5인 경우도 있어서 마지막 fallback\n",
    "    return TabPFNRegressor()\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_reg_rowwise(model, X):\n",
    "    # \"테스트-테스트 상호작용(트랜스덕티브) 가능성\"을 최대한 피하려고 row-by-row\n",
    "    preds = []\n",
    "    for i in range(X.shape[0]):\n",
    "        preds.append(float(model.predict(X[i:i+1])[0]))\n",
    "    return np.array(preds, dtype=np.float32)\n",
    "\n",
    "def build_tabpfn_relation_residual_repr(\n",
    "    Xtr_in_s, Xte_s, k_targets=8, max_train_points=512, seed=0\n",
    "):\n",
    "    set_seed(seed)\n",
    "    d = Xtr_in_s.shape[1]\n",
    "    targets = pick_target_columns_by_variance(Xtr_in_s, k=k_targets, seed=seed)\n",
    "    print(\"Selected target columns:\", targets)\n",
    "\n",
    "    # train subsample (속도/안정)\n",
    "    if Xtr_in_s.shape[0] > max_train_points:\n",
    "        rng = np.random.default_rng(seed)\n",
    "        idx = rng.choice(Xtr_in_s.shape[0], size=max_train_points, replace=False)\n",
    "        Xtr_fit = Xtr_in_s[idx]\n",
    "        print(f\"Subsample train inliers: {Xtr_in_s.shape[0]} -> {Xtr_fit.shape[0]}\")\n",
    "    else:\n",
    "        Xtr_fit = Xtr_in_s\n",
    "\n",
    "    Ztr = np.zeros((Xtr_in_s.shape[0], k_targets), dtype=np.float32)\n",
    "    Zte = np.zeros((Xte_s.shape[0], k_targets), dtype=np.float32)\n",
    "\n",
    "    for t_i, j in enumerate(targets):\n",
    "        # 입력: X without j, 타겟: x_j\n",
    "        Xtr_inp = np.delete(Xtr_fit, j, axis=1)\n",
    "        ytr = Xtr_fit[:, j]\n",
    "        Xtr_inp_full = np.delete(Xtr_in_s, j, axis=1)\n",
    "        Xte_inp = np.delete(Xte_s, j, axis=1)\n",
    "\n",
    "        reg = tabpfn_regressor_v25()\n",
    "\n",
    "        print(f\"\\n[TabPFN v2.5] Fit regressor for col={j} with X shape {Xtr_inp.shape} -> y shape {ytr.shape}\")\n",
    "        reg.fit(Xtr_inp, ytr)\n",
    "\n",
    "        # 예측 (row-wise로 안전하게)\n",
    "        yhat_tr = predict_reg_rowwise(reg, Xtr_inp_full)\n",
    "        yhat_te = predict_reg_rowwise(reg, Xte_inp)\n",
    "\n",
    "        # residual (절대오차)\n",
    "        Ztr[:, t_i] = np.abs(Xtr_in_s[:, j] - yhat_tr)\n",
    "        Zte[:, t_i] = np.abs(Xte_s[:, j] - yhat_te)\n",
    "\n",
    "        print(\"  residual stats (test): mean\", float(Zte[:,t_i].mean()), \"max\", float(Zte[:,t_i].max()))\n",
    "\n",
    "    meta = {\"targets\": targets, \"k_targets\": k_targets, \"max_train_points\": max_train_points}\n",
    "    return Ztr, Zte, meta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1331df0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected target columns: [8, 7, 0, 6, 4, 5]\n",
      "Subsample train inliers: 355 -> 256\n",
      "\n",
      "[TabPFN v2.5] Fit regressor for col=8 with X shape (256, 8) -> y shape (256,)\n",
      "  residual stats (test): mean 0.9817519187927246 max 15.274371147155762\n",
      "\n",
      "[TabPFN v2.5] Fit regressor for col=7 with X shape (256, 8) -> y shape (256,)\n",
      "  residual stats (test): mean 1.6046957969665527 max 8.23944091796875\n",
      "\n",
      "[TabPFN v2.5] Fit regressor for col=0 with X shape (256, 8) -> y shape (256,)\n",
      "  residual stats (test): mean 1.0966465473175049 max 4.030312538146973\n",
      "\n",
      "[TabPFN v2.5] Fit regressor for col=6 with X shape (256, 8) -> y shape (256,)\n",
      "  residual stats (test): mean 1.3231803178787231 max 6.23377799987793\n",
      "\n",
      "[TabPFN v2.5] Fit regressor for col=4 with X shape (256, 8) -> y shape (256,)\n",
      "  residual stats (test): mean 0.9214044213294983 max 6.729058265686035\n",
      "\n",
      "[TabPFN v2.5] Fit regressor for col=5 with X shape (256, 8) -> y shape (256,)\n",
      "  residual stats (test): mean 1.6779112815856934 max 7.18416166305542\n",
      "\n",
      "Ztr shape: (355, 6) Zte shape: (137, 6)\n",
      "Zte[0]: [0.003545   0.04705229 0.6819128  1.0835435  1.1032985  0.01303393]\n",
      "meta: {'targets': [8, 7, 0, 6, 4, 5], 'k_targets': 6, 'max_train_points': 256}\n",
      "\n",
      "TabPFN-residual + IForest metrics: {'auroc': 0.9948501872659176, 'auprc': 0.991130526541157}\n",
      "scores head: [0.36017476 0.736406   0.39048065 0.33093323 0.33708231 0.71931868\n",
      " 0.71540522 0.33808171 0.33093323 0.49629162]\n"
     ]
    }
   ],
   "source": [
    "set_seed(0)\n",
    "\n",
    "Ztr, Zte, meta = build_tabpfn_relation_residual_repr(\n",
    "    Xtr_in_s, Xte_s,\n",
    "    k_targets=6,          # 처음엔 4~8 추천\n",
    "    max_train_points=256, # 먼저 작게\n",
    "    seed=0\n",
    ")\n",
    "\n",
    "print(\"\\nZtr shape:\", Ztr.shape, \"Zte shape:\", Zte.shape)\n",
    "print(\"Zte[0]:\", Zte[0])\n",
    "print(\"meta:\", meta)\n",
    "\n",
    "# residual space에서 IForest\n",
    "m_if_z = fit_iforest(Ztr, seed=0)\n",
    "s_if_z = score_iforest(m_if_z, Zte)\n",
    "\n",
    "print(\"\\nTabPFN-residual + IForest metrics:\", metrics(yte, s_if_z))\n",
    "print(\"scores head:\", s_if_z[:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "551cb716",
   "metadata": {},
   "source": [
    "##### 정보 섞이는지 간단 check\n",
    "- TabPFN이 내부적으로 predict 시 test batch를 같이 처리하면서 query-query attention이 있으면, 배치 크기에 따라 결과가 달라질 수 있어. 그래서 위에서는 안전하게 row-wise로 했어.\n",
    "\n",
    "아래는 row-wise vs 한번에(batch) 예측 결과가 얼마나 다른지 보는 체크야(차이가 0이 아니면 “상호작용 가능성” 시그널)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5cffd9c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max |batch - rowwise| = 0.002199709415435791\n",
      "first 5 batch: [-0.13281395  0.8498919  -0.1249333  -0.132583   -0.13314563]\n",
      "first 5 row  : [-0.13284117  0.84813434 -0.12503633 -0.13259807 -0.1331743 ]\n"
     ]
    }
   ],
   "source": [
    "# 한 컬럼(j)으로만 quick check\n",
    "j = meta[\"targets\"][0]\n",
    "Xtr_inp = np.delete(Xtr_in_s, j, axis=1)\n",
    "ytr = Xtr_in_s[:, j]\n",
    "Xte_inp = np.delete(Xte_s, j, axis=1)\n",
    "\n",
    "reg = tabpfn_regressor_v25()\n",
    "reg.fit(Xtr_inp[:256], ytr[:256])\n",
    "\n",
    "# batch 예측\n",
    "yhat_batch = reg.predict(Xte_inp)\n",
    "\n",
    "# row-wise 예측\n",
    "yhat_row = predict_reg_rowwise(reg, Xte_inp)\n",
    "\n",
    "diff = np.max(np.abs(yhat_batch - yhat_row))\n",
    "print(\"max |batch - rowwise| =\", float(diff))\n",
    "print(\"first 5 batch:\", yhat_batch[:5])\n",
    "print(\"first 5 row  :\", yhat_row[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32563c30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gad",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
